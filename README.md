# Курс "Специалист по Data Science". Секция "Машинное обучение"

Этот репозиторий содержит материалы по курсу "Машинное обучение", читаемому в рамках программы профессиональной переподготовки по направлению "Специалист по Data Science" ВШЭ.

Преподаватели: Колмагоров Евгений, Кочарян Давид


## Занятия

|    Дата    | Номер | Тема                                                         | Материалы                                                    | ДЗ                                                           |
| :--------: | :---: | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
|  7 октября  |  01   | Введение в машинное обучение.Основные понятия.Типы задач. Разбиение на train и test. Обучение и оценка качества модели.| <ul><li>[Занятие1](Занятие\ 01)</li></ul>| <ul><li>[ДЗ1](Занятие\ 01)</li><li>Мягкий дедлайн: 21 октября</li><li>Жёский дедлайн: 4 ноября</li></ul> |
|  14 октября  |  02   | Линейные методы регрессии.Функционал ошибки. Градиентный спуск. | <ul><li> [Занятие 2](Занятие\ 02)</li></ul> | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
|  21 октября  |  03   | Метрики качества. Переобучение. Регуляризация | <ul><li>[Занятие 3](Занятие\ 03)</li></ul> | <ul><li>[ДЗ2](Занятие\ 3/ДЗ)</li><li>Мягкий дедлайн: 4 ноября</li><li>Жёский дедлайн: 18 ноября</li></ul> |
|  28 октября |  04   | Регуляризация в линейной регрессии. Кросс-валидация. | <ul><li>[Занятие 4](Занятие\ 04)</li></ul> | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
|  11 ноября |  05   | Линейные методы классификации (бинарная). Логистическая регрессия. Метрики качества. | <ul><li>[Занятие 5](Занятие\ 05)</li></ul>  | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
|  18 ноября |  06   | SVM. Многоклассовая классификация. | <ul><li>[Занятие 6](Занятие\ 06)</li></ul> | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
| 25 ноября |  07   | Нелинейные методы классификации. Байесовский классификатор. KNN. Kernel SVM. | <ul><li>[Занятие 7](Занятие\ 07)</li></ul>  | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
|  2 декабря |  08   | Деревья решений. Критерии информативности. | <ul><li>[Занятие 8](Занятие\ 08)</li></ul>  | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
|  9 декабря |  09  | Ансамблевые методы. Случайный лес, бэггинг. Разложение ошибки на bias, variance. | <ul><li>[Занятие 09](Занятие\ 9)</li></ul>  | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
|  16 декабря |  10   | Градиентный бустинг. XGBoost, CatBoost, LIghtGBM | <ul><li>[Занятие 10](Занятие\ 10)</li></ul> | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
|  23 декабря |  11   | Обучение без учителя. Кластеризация и визуализация данных. Метрики качества. | <ul><li>[Занятие 11](Занятие\ 11)</li></ul>  | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
| 13 января |  12   | Понижение размерности. PCA. Детектирование аномалий. | <ul><li>[Занятие 12](Занятие\ 12)</li></ul> | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
| 20 января |  13   | Рекомендательные системы. | <ul><li>[Занятие 13](Занятие\ 13)</li></ul>  | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
| 27 января |  14   | Статистический взгляд на модели МО. Анализ временных рядов. | <ul><li>[Занятие 14](Занятие\ 14)</li></ul>  | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |

## Полезные материалы
<ul>
    <li>[Хендбук от Яндекса «Основы Python»](https://academy.yandex.ru/handbook/python).</a> Классный интерактивный тренажёр для повторения основ программирования.</li>
    <li>[Учебник](https://academy.yandex.ru/handbook/ml) по машинному обучению от ШАД Яндекса . Красиво свёрстанный материал от ведущих специалистов ML</li>
    <li>Учебник An Introduction to Statistical Learning от всемирно известных профессоров из Стэнфордского университета Hastie, Tibshirani [https://www.statlearning.com/](https://www.statlearning.com/) В 2023 году вышло издание на Python! Материалы открыты и доступны для скачивания.</li>
    <li>[Конспекты лекций Евгения Соколова](https://github.com/esokolov/ml-course-hse/tree/master/2021-fall/lecture-notes), научного руководителя Центра непрерывного образования, академического руководителя бакалаврской программы «Прикладная математика и информатика» нашего факультета </li>
</ul>