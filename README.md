# Курс "Специалист по Data Science". Секция "Машинное обучение"

Этот репозиторий содержит материалы по курсу "Машинное обучение", читаемому в рамках программы профессиональной переподготовки по направлению "Специалист по Data Science" ВШЭ.

Преподаватели: Колмагоров Евгений, Кочарян Давид


## Занятия

|    Дата    | Номер | Тема                                                         | Материалы                                                    | ДЗ                                                           |
| :--------: | :---: | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
|  7 октября  |  01   | Введение в машинное обучение.Основные понятия.Типы задач. Разбиение на train и test. Обучение и оценка качества модели.| <ul><li>[Занятие1](Занятие1)</li></ul>| <ul><li>[ДЗ1](Занятие1/hometask1_pandas)</li><li>Мягкий дедлайн: 21 октября</li><li>Жёский дедлайн: 4 ноября</li></ul> |
|  14 октября  |  02   | Линейные методы регрессии.Функционал ошибки. Метрики качества. Переобучение. | <ul><li> [Занятие2](Занятие2)</li></ul> | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
|  21 октября  |  03   | Градиентный спуск.  | <ul><li>[Занятие3](Занятие3)</li></ul> | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
|  28 октября |  04   | Регуляризация в линейной регрессии. Кросс-валидация. Кодирование категориальных признаков. | <ul><li>[Занятие4](Занятие4)</li></ul> | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
|  11 ноября |  05   | Линейные методы классификации (бинарная). Логистическая регрессия. Метрики качества. | <ul><li>[Занятие5](Занятие5)</li></ul>  | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
|  18 ноября |  06   | SVM. Многоклассовая классификация. | <ul><li>[Занятие6](Занятие6)</li></ul> | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
| 25 ноября |  07   | Нелинейные методы классификации. Байесовский классификатор. KNN. Kernel SVM. | <ul><li>[Занятие7](Занятие7)</li></ul>  | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
|  2 декабря |  08   | Деревья решений. Критерии информативности. | <ul><li>[Занятие8](Занятие8)</li></ul>  | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
|  9 декабря |  09  | Ансамблевые методы. Случайный лес, бэггинг. Разложение ошибки на bias, variance. | <ul><li>[Занятие9](Занятие9)</li></ul>  | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
|  16 декабря |  10   | Градиентный бустинг. XGBoost, CatBoost, LIghtGBM | <ul><li>[Занятие10](Занятие10)</li></ul> | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
|  23 декабря |  11   | Обучение без учителя. Кластеризация и визуализация данных. Метрики качества. | <ul><li>[Занятие11](Занятие11)</li></ul>  | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
| 13 января |  12   | Понижение размерности. PCA. Детектирование аномалий. | <ul><li>[Занятие12](Занятие12)</li></ul> | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
| 20 января |  13   | Рекомендательные системы. | <ul><li>[Занятие13](Занятие13)</li></ul>  | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |
| 27 января |  14   | Статистический взгляд на модели МО. Анализ временных рядов. | <ul><li>[Занятие14](Занятие14)</li></ul>  | ( ͡▀̿ ̿ ͜ʖ ͡▀̿ ̿) |